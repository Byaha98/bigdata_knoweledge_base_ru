

# 270-290? (уточнить, вернутся к записи)  DWH analyst

# В Clickhouse есть таблицы, шардированные по разным полям, какую операцию надо применить, чтобы соединить их?


Здесь нужен broadcast
## Broadcast паттерн в MPP архитектуре

Broadcast JOIN — это классический паттерн в MPP системах. Основная идея простая:[](https://celerdata.com/glossary/massively-parallel-processing-mpp)​

**Когда одна таблица маленькая (dimension table), а другая большая (fact table):**

1. **Broadcast (разброс)**: отправить маленькую таблицу на все узлы параллельно
    
2. **Local Join**: каждый узел выполняет JOIN со своим сегментом большой таблицы
    
3. **Gather**: собрать результаты обратно
    

Почему это работает в MPP:[](https://celerdata.com/glossary/massively-parallel-processing-mpp)​

- Каждый узел обрабатывает JOIN параллельно (не нужно ждать других узлов)
    
- Нет сложной пересылки данных между узлами для поиска совпадений


-- events распределена по user_id
-- products распределена по product_id
-- Используем GLOBAL JOIN чтобы broadcast маленькую таблицу (products)

SELECT 
    e.user_id,
    p.product_name,
    e.event_type
FROM events_distributed e
GLOBAL JOIN products_distributed p ON e.product_id = p.product_id;

-- ClickHouse broadcast таблицу products на все шарды events
-- Затем выполняет JOIN локально на каждом шарде events


# Как в гринпламе оптимально вывести уникальные записи из большой таблицы без redistribution motion?


Важно не допустить **Redistribution Motion** — это операция в Greenplum, когда каждый сегмент повторно хеширует данные и отправляет строки в другие сегменты в соответствии с хеш-ключом для группировки или соединения.


Redistribution достаточно невыгодные операции. Они выполняются при каждом запуске запроса. Рекомендуется избегать их. Увидев в плане запроса такие пункты, стоит обратить внимание на ключи распределения. Также операции distinct и union являются причиной motions.

## **Использовать GROUP BY вместо DISTINCT** (более оптимизируемо)


Если `GROUP BY` совпадает с ключом распределения (`DISTRIBUTED BY (col1)`), Greenplum выполняет расчеты параллельно на всех сегментах без пересылки данных между ними.

`SELECT column_name FROM large_table GROUP BY column_name

GROUP BY часто работает эффективнее DISTINCT в Greenplum, особенно для больших таблиц. Greenplum параллелизирует операцию агрегации на всех сегментах, затем объединяет результаты на мастер-узле

Для дедупликации:

SELECT user_id, 
MAX(event_id) as latest_event_id, -- ID последнего события 
MAX(event_date) as latest_date FROM events 
GROUP BY user_id;

Если у нас user id - это должно быть уникальное поле без повторений, мы можем сделать его ключом распределения и по нему делать group by

-- 1. Создать таблицу с правильным distribution key
CREATE TABLE events (
    event_id BIGINT,
    user_id BIGINT,  -- Этот столбец часто в GROUP BY/DISTINCT
    event_date DATE,
    event_type VARCHAR
)
DISTRIBUTED BY (user_id);

-- 2. Использовать GROUP BY вместо DISTINCT
SELECT user_id, 
MAX(event_id) as latest_event_id, -- ID последнего события 
MAX(event_date) as latest_date FROM events 
GROUP BY user_id;


UNION vs UNION ALL

UNION ALL  **Включает все строки**, в том числе повторяющиеся, из обоих результирующих наборов.

UNION  **Возвращает только уникальные строки**, удаляя повторяющиеся.


Виды джоинов и количество строк мин макс

Есть хороший пост, это объясняющий в другом тг канале

https://t.me/chtotonainzhenernom/157